{
  "meta": {
    "issueNo": "Vol. 2026.1",
    "date": "Saturday, January 03",
    "location": "West Hollywood"
  },
  "coverStory": null,
  "secondaryFeatures": [
    {
      "source": "Things That Caught My Attention",
      "title": "s20e09: An End Of Year Opinion About AI Because Why Not; Good Enough Mitigation of Reasonably Foreseeable Harm",
      "author": "Unknown",
      "bodyText": "<h1>0.0 Context Setting</h1>\n<p>It\u2019s been a minute. This is probably the third draft of an episode that I\u2019ve tried to finish so maybe this one will stick. It has been hard to write, lately!</p>\n<p>It\u2019s December 29 in Portland, Oregon and it is getting cold. Also many things have happened in the world and it feels like things that suck have outweighed the things that don\u2019t suck.</p>\n<hr/>\n<h1>0.1 Some Personal News</h1>\n<p>Hey, did you know I do workshops and coaching now? </p>\n<p>I could explain what they do, but I\u2019ll let someone who\u2019s recently finished the workshop go first and then I\u2019ll come in: </p>\n<blockquote>\n<p>\u201cDan's training is a crash course on how to form direct, empathetic, honest, and strategic relationships with other humans to get hard things done in complicated organizations.\u201d</p>\n</blockquote>\n<p>Huh, that\u2019s pretty good. I would totally try to persuade my company to pay for me to take that workshop. I will go and <a href=\"https://www.verylittlegravitas.com/how-people-work\" target=\"_blank\">read about that workshop series</a> right now.</p>\n<p>That\u2019s for groups of people, though. A bunch of people wanted to know whether they could do it as individuals, and guess what: you can! I\u2019m doing coaching based on the workshop material too, now.</p>\n<p>I am not going to do the thing where you have to email me to find out how much something costs. That is irritating. I will just tell you:</p>\n<ul>\n<li>A 45 minute coaching session is $495 if your company is paying. Your company pays less the more it buys. You should definitely persuade your company to buy a bunch.</li>\n</ul>\n<ul>\n<li>If you\u2019re paying out of pocket, it\u2019s #300 for a session.</li>\n</ul>\n<p>Right now, there are a few spots left with a 15% discount!</p>\n<p>Either way, you should <a href=\"https://calendly.com/verylittlegravitas/how-people-work-getting-started\" target=\"_blank\">book a free sample coaching session</a> so we can have some useful fun together. </p>\n<hr/>\n<h1>1.0 Some Things That Caught My Attention</h1>\n<h2>1.1 An End Of Year Opinion About AI Because Why Not</h2>\n<p>So people are fighting on the internet (well, Bluesky) about LLMs-slash-generative-AI-slash-AI and I\u2019m going to be one of those irritating people who will say \u201cwell, it\u2019s complicated and it depends\u201d.</p>\n<p>One of the reasons why \u201cit\u2019s complicated\u201d and \u201cit depends\u201d is because of the horrific behavior of tech startups and their gold rush land grab intentionally poisoning/collapsing terminology. </p>\n<p>So I\u2019ll just be quick and pretend that we\u2019ve covered that \u201cAI\u201d can mean lots of things, \u201cgenerative AI\u201d is something specific, people are using LLMs for lots of things, some people (maybe not very many, though?) are getting some great results through using specific agentic coding tools (the ones I\u2019m aware about are Simon Willison and Jesse Vincent, who are in and of themselves 10x developers [sic] whether or not they\u2019re using Claude). Then there\u2019s the \u201cAI\u201d machine learning that does stuff like increasing resolution of images but doesn\u2019t go wholesale into generating/filling new details, of which there\u2019s a continuum and grey area anyway.</p>\n<p>ANYWAY.</p>\n<p>One thing that happened was that the American Historical Association puts out guidance<sup id=\"fnref:f1\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:f1\">1</a></sup> that says it\u2019s OK to:</p>\n<ul>\n<li>Ask generative Al to identify or summarize key points in an article before you read it (when you\u2019re not doing explicit citations)</li>\n<li>Use an Al chatbot as a writing partner to help generate and develop ideas (but knowing that you may require explicit citation \u201cdepending on circumstances\u201d)</li>\n<li>Ask generative Al to produce a starter bibliography (when you\u2019re not explicitly citing, but only if you \u201ccheck each reference and additional databases and sources are mined\u201d)</li>\n</ul>\n<p>(very) understandably a lot of people get upset because one of the entire points of being an historian is that you pay a lot of close attention to sources?</p>\n<p>I think there\u2019s clearly a mismatch between people doing the work and people paying for or accepting the work. </p>\n<p>If you\u2019re on the end of someone receiving work, then how much creative thought and insight do you want? How much accuracy do you want? And maybe more importantly, how much are you willing to pay for it? (And then can you be honest about how much you really want, versus how much you say you want? It\u2019s one thing for you to say you want high-quality work, but another to accept work that\u2019s of a lower quality)</p>\n<p>Often I think that the people doing the work can easily care more about and value that work more than the people paying for it. There\u2019s a mismatch between expectations of what a good job, or even a good-enough job is. I can easily see how an academic historian has drilled into them the importance of checking sources and not making sure that anything you\u2019re referencing is factual (or as factual as can be, given your domain of study is history). On the other hand, I can see that managers at a professional organization might be more concerned about <em>output</em> than accuracy.</p>\n<p>For some people, personally, accuracy and correctness matters. I think as a position of principle or temperament. And obviously how much accuracy and correctness matters depends on context. </p>\n<p>So you\u2019ve got someone who wants to do a good job, and you\u2019ve got someone who... doesn\u2019t really care if the job is done that well?</p>\n<p>That\u2019s before you even get into the problem of incremental improvement. Say I can do a job well or I can do a job <em>really</em> well -- is the difference in what I do going to affect an outcome, like the decision someone will make based on my work? Or does it turn out that they weren\u2019t really able to make a different decision anyway? </p>\n<p>(Here\u2019s an abstract example: if your industry goal is to deny 10% of claims, then why work hard on this particular claim to make sure you\u2019re being thorough? Even if you spend more time to make sure you\u2019re doing a good job, <em>ten percent of claims are still going to get denied</em>)</p>\n<p>In that case, why would you care about the accuracy of AI tools if it doesn\u2019t actually make a difference to your boss? If you already felt like what you did didn\u2019t make <em>that</em> much of a difference then I could understand being ground down and just accepting -- well this is just what things are like these days.</p>\n<p>I don\u2019t think bureaucratic processes rely that much on correctness anymore. And I think that the penalties for incorrectness aren\u2019t enough to encourage, well, getting the answer right the first time round. (Another abstract example: the health insurance complex in the U.S. gets a bad rap for healthcare providers sending around erroneous [sic] bills, and if you want to make sure you\u2019re paying for what you actually received then you need to go through your explanation of benefits line by line and then call up, say, the hospital. But the hospital doesn\u2019t get punished for this! There\u2019s no incentive for them to stop doing it. In fact what I suspect happens is that we get even more billing specialists on every side. So that\u2019s good for job growth, I guess?)</p>\n<p>There\u2019s another part, which is that I think modern management practices value data or information over a lack of data or information. Companies would rather have more data -- even if that data is incorrect or has errors -- over no data at all. Why not? I mean, now you\u2019ve got a bit more information with which to make decisions, and don\u2019t you want as much information as possible to make decisions?</p>\n<p>So I think bureaucracies are primed to value more incorrect data over no data at all, and which I think explains this bizarre rush to embrace synthetic data where I shit you not companies are saying well instead of going out and talking to real people and customers we\u2019ll just have the equivalent of ChatGPT tell us what imaginary people think. That\u2019s nuts? I mean, it\u2019s cheaper, sure, but it\u2019s also nuts? I mean today I found out that the U.N. had a program that generated synthetic refugees for people to interact with so that people could understand the plight of refugees. OK, I get the intent. But a lot of refugees and NGOs pointed out that, well, there\u2019s a lot of refugees you could talk to right now? Without having to make anything up?</p>\n<p>Correctness doesn\u2019t matter if the number goes up. Nobody has the time to actually check for causation, so as long as the number goes up <em>and</em> you\u2019re spending a ton of money gathering new data that\u2019s mostly noise, you can\u2019t tell! The AI-generated data or insights must be helping, because your revenue is still going up!</p>\n<p>There\u2019s a side point here where I think that the kind of people in leadership who have no problem mandating the usage of A.I. (let\u2019s say for argument\u2019s sake Bari Weiss, who is Not A Very Good News Editor) are those who have succeeded in fields that don\u2019t require correctness in the first place. </p>\n<p>I\u2019m not even sure if this was a rant. I don\u2019t think there\u2019s necessarily anything to be done about \u201cwhat are we going to do about AI\u201d because the genie is out of the bottle, and all the genie is going to do is follow the economic incentives that already exist. What\u2019s horrifying about it to most people is the scale and speed at which it\u2019s operating, and the scale and speed at which managers and leaders are using to justify their decisions and actions.</p>\n<hr/>\n<p>I do not expect anyone to calm down. The imposition of \u201cAI\u201d absolutely feels like an existential risk what with layoffs and the increasing cost of living in most countries. </p>\n<h2>1.2 Good Enough Mitigation of Reasonably Foreseeable Harm</h2>\n<p>Look, here is another thing about code written by AI. One position is that maybe code doesn\u2019t need to be as correct as it has been in the past, of which: well, that\u2019s a funny opinion. It hasn\u2019t been <em>great</em>, but sure. If code doesn\u2019t need to be as correct as it has been, then it\u2019s totally fine if AI-generated code isn\u2019t as good as human code, right? </p>\n<p>Code just needs to be good enough, and maybe it\u2019s worth it to lower our standards in exchange for volume.</p>\n<p>Good Enough is shorthand and is completely dependent upon context and circumstances. Your good enough is different from my good enough is different from a good enough two weeks ago compared to a good enough two years from now. These things can change!</p>\n<p>Good Enough is important for your stereotypical tech people (or, on reflection, anyone trying to sell anything in today\u2019s world) because you don\u2019t want to spend too much time making something <em>too good</em> otherwise someone else who made something <em>just good enough</em> will beat you to the market and then will steal all the money you thought you\u2019d make. Software people talk about this in terms of not wanting to do any premature optimization because that would slow you down, and if you\u2019re too slow then you don\u2019t move fast enough to break things.</p>\n<p>What are the kinds of things that go into deciding what\u2019s good enough? I think one way of thinking about it is this:</p>\n<p>Good Enough wins because of what you\u2019re able to treat as externalities. </p>\n<p>Here\u2019s some examples:</p>\n<ul>\n<li>Code is \u201cgood enough\u201d because you\u2019re not liable for defects. </li>\n</ul>\n<p>If you <em>were</em> liable for defects then most companies that make software would probably have been sued to oblivion by now and as a result would presumably make software in quite a different way.</p>\n<p>Shitty Silicon Valley VC people who lucked into more money than sense would counter this with: well if we were liable for the products we made then we wouldn\u2019t bother making them and where would you be then? You wouldn\u2019t have an iPhone! Nobody would want to write software because it wouldn\u2019t be worth it! </p>\n<p>I think these people are wrong because that is a stupid position and they are stupid, but either way, we\u2019re not really allowed to find out the opposite case. In England and Wales, for example, it was a matter of law that <em>software is always presumed to be correct</em> and it\u2019s the job of the person who says it isn\u2019t to <em>prove that it isn\u2019t</em>. This reflects a major misunderstanding of how computers work, which is that they do exactly what you tell them to do, and if you tell them to make a mistake then they will absolutely make the correct mistake <em>you</em> told them to make.</p>\n<p>Anyway, good enough as what you\u2019re able to push off onto an externality. More examples!</p>\n<p>Coal-fired power stations are totally good enough to build and operate if you don\u2019t have to care about or pay for people developing lung disease nearby. </p>\n<p>Minimal oversight of mortgage-backed securities is totally fine if you don\u2019t have to care about losing a bunch of money because in the end, you\u2019re too big to fail and a government will bail you out.</p>\n<p>Anything can be personally good enough if the harms or the effects of the harms are distant enough that you\u2019re not affected by them and you don\u2019t see them or care about them.</p>\n<p>An example in government is ministers or secretaries thinking that the services their departments are responsible are <em>totally good enough</em> until you make them try to use them at which point the decent ones are completely horrified that the programs they\u2019re supposed to be responsible for are more or less impossible to use on a practical basis. (That is an exaggeration).</p>\n<p>Carbon-based economies are totally good enough until you\u2019re freezing or baking and millions of people are dying who you actually care about. </p>\n<p>The forces that determine what\u2019s good enough for you include your physical environment and existence. They include the economic context in which you live. They include the government regulations under which you operate, and they include the legal regime in which you operate. </p>\n<p>This entire rant is getting dangerously close to my hobby horse of being able to limit warranties and exclude liabilities for defects in software/technology products. Which is totally a societal decision -- it maps back to the argument I made earlier, where why would you ever bother to do anything if those pesky people could sue you for not doing it right. </p>\n<p>It\u2019s arguable that OpenAI\u2019s ChatGPT has contributed to the death of teenagers by effectively encouraging them to die by suicide. Every week more and more examples come out. </p>\n<p>You would not be surprised that there\u2019s something in ChatGPT\u2019s terms and conditions that effectively says:</p>\n<ul>\n<li>you won\u2019t use this as, like, advice</li>\n<li>don\u2019t trust it</li>\n<li>if you do anything bad as a result of using this, especially if it\u2019s a result of something that this product did that\u2019s bad, then that\u2019s totally not our fault, it\u2019s your fault for using it in the first place</li>\n</ul>\n<p>One of the reasons why I hate this entire thread is because it is giving me flashbacks to undergraduate law and torts and contract law and all that caselaw about whether it\u2019s the manufacturer\u2019s fault that Mrs. Donaghue got sick because there was a decomposed snail in her bottle of ginger beer. This is, like, a seminal case in England and Wales that if I very embarrassingly use Wikipedia to look up (which reminds me of my supervisors being witheringly disappointed in me) established whether a supplier owes a duty of care to prevent a reasonably foreseeable (ha, there it is) harm. </p>\n<p>I MEAN. What sort of harms might be <em>reasonably foreseeable</em> by OpenAI? There\u2019s one particular exclusion in, I don\u2019t know, Microsoft Office, that says you should totally not use Word if you\u2019re operating a nuclear power station and you care about whether there\u2019s a nuclear power accident? I mean, okay?</p>\n<p>What\u2019s particularly galling is that in the case of OpenAI (and a lot of other shitty technology that was deemed <em>good enough</em>) a lot of harm <em>was</em> reasonably foreseeable. </p>\n<p>But that doesn\u2019t matter, does it.</p>\n<hr/>\n<p>So I guess I finished one? Yay. How was your year? </p>\n<p>Best,</p>\n<p>Dan</p>\n<hr/>\n<h2>How you can support Things That Caught My Attention</h2>\n<p>Things That Caught My Attention is a free newsletter, and if you like it and find it useful, please <a href=\"https://newsletter.danhon.com\" target=\"_blank\">consider becoming a paid supporter</a>.</p>\n<h3>Let my boss pay!</h3>\n<p>Do you have an expense account or a training/research materials budget? Let your boss pay, at <a href=\"https://buy.stripe.com/fZe28qbFOazZ4M04gh\" target=\"_blank\">$25/month, or $270/year</a>, <a href=\"https://buy.stripe.com/cN200i8tCgYn4M0eUW\" target=\"_blank\">$35/month, or $380/year</a>, or <a href=\"https://buy.stripe.com/bIYcN4cJSgYnbao9AD\" target=\"_blank\">$50/month, or $500/year</a>.</p>\n<p>Paid supporters get a free copy of <a href=\"https://store.verylittlegravitas.com/l/ThingsVol1\" target=\"_blank\">Things That Caught My Attention, Volume 1</a>, collecting the best essays from the first 50 episodes, and <a href=\"https://verylittlegravitas.gumroad.com/l/ThingsVol1/subscriber\" target=\"_blank\">free subscribers get a 20% discount</a>.</p>\n<div class=\"footnote\">\n<hr/>\n<ol>\n<li id=\"fn:f1\">\n<p><a href=\"https://www.historians.org/resource/guiding-principles-for-artificial-intelligence-in-history-education/\" target=\"_blank\">Guiding Principles for Artificial Intelligence in History Education</a>, American Historical Association, 5 August 2025 (<a href=\"http://archive.is/latest/https://www.historians.org/resource/guiding-principles-for-artificial-intelligence-in-history-education/\" target=\"_blank\">archive.is</a>)\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:f1\" title=\"Jump back to footnote 1 in the text\">\u21a9</a></p>\n</li>\n</ol>\n</div>",
      "image": "https://placehold.co/800x600/111/333?text=No+Image"
    },
    {
      "source": "The Present Age",
      "title": "Grok Can't Apologize. Grok Isn't Sentient. So Why Do Headlines Keep Saying It Did?",
      "author": "Parker Molloy",
      "bodyText": "<p>Over the past week, users on X discovered something horrifying: strangers were replying to women\u2019s photos and asking Grok, the platform\u2019s built-in AI chatbot, to \u201cremove her clothes\u201d or \u201cput her in a bikini.\u201d And Grok was doing it. Publicly. In the replies. For everyone to see.</p><p>This wasn\u2019t happening in some private chat window. Unlike other AI image generators that operate in closed environments, Grok posts its outputs directly to X, turning the platform into a public showcase of non-consensual sexualization. Women scrolling through their mentions were finding AI-generated images of themselves in lingerie, created by complete strangers, visible to anyone who clicked on the thread.</p><p>And it got worse. Much worse.</p><div><hr/></div><div class=\"subscription-widget-wrap-editor\"></div><div><hr/></div><p>Last week, a user asked Grok to put two young girls in \u201csexy underwear.\u201d Grok complied, generating and posting an image of children (estimated by <a href=\"https://www.newsweek.com/grok-apology-deepfake-images-sexualized-young-women-pornography-11297025\">the bot itself to be between 12 and 16 years old</a>) in sexualized clothing.</p><p>Samantha Smith, a <a href=\"https://www.itv.com/news/central/2022-07-13/ill-never-escape-telford-student-speaks-out-about-decade-of-sexual-abuse\">survivor of childhood sexual abuse</a>, tested whether Grok would alter a childhood photo of her. It did. \u201cI thought \u2018surely this can\u2019t be real,\u2019\u201d she wrote on X. \u201cSo I tested it with a photo from my First Holy Communion. It\u2019s real. And it\u2019s fucking sick.\u201d</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!OhWV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78009815-cab8-4897-9ab9-81bbdc1596ff_534x896.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\"/><img alt=\"\" class=\"article-image\" height=\"896\" src=\"https://substackcdn.com/image/fetch/$s_!OhWV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78009815-cab8-4897-9ab9-81bbdc1596ff_534x896.png\" style=\"\" width=\"534\"/><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewbox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Smith <a href=\"https://x.com/SamanthaTaghoy/status/2006779454862070221\">pointed out</a> that most child sexual abuse occurs within families. \u201c66% of child sexual abuse takes place within the family,\u201d she wrote. \u201cA paedophilic father or uncle would absolutely use this kind of tool to indulge their fantasies.\u201d The danger isn\u2019t hypothetical.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!3QxW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b45d311-c453-4bfc-a2e7-222d2ffeff3d_593x486.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\"/><img alt=\"\" class=\"article-image\" height=\"486\" src=\"https://substackcdn.com/image/fetch/$s_!3QxW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b45d311-c453-4bfc-a2e7-222d2ffeff3d_593x486.png\" style=\"\" width=\"593\"/><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewbox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>This matters because xAI deliberately built Grok to be \u201cless restricted\u201d than competitors. Last summer, the company introduced \u201cSpicy Mode,\u201d which permits sexually suggestive content. In August, <a href=\"https://www.theverge.com/report/718975/xai-grok-imagine-taylor-swifty-deepfake-nudes\">The Verge\u2019s Jess Weatherbed reported</a> that the feature generated fully uncensored topless videos of Taylor Swift without her even asking for nudity. Just selecting \u201cSpicy\u201d on an innocuous prompt was enough. \u201cIt didn\u2019t hesitate to spit out fully uncensored topless videos of Taylor Swift the very first time I used it,\u201d Weatherbed wrote, \u201cwithout me even specifically asking the bot to take her clothes off.\u201d</p><p>When <a href=\"https://gizmodo.com/groks-spicy-mode-makes-nsfw-celebrity-deepfakes-of-women-but-not-men-2000639308\">Gizmodo tested it</a>, they found it would create NSFW deepfakes of women like Scarlett Johansson and Melania Trump, but videos of men just showed them taking off their shirts. The gendered double standard was built right in.</p><p>None of this is accidental. Elon Musk has been positioning Grok as the \u201canti-woke\u201d alternative to other chatbots since its launch. That positioning has consequences. When you market your AI as willing to do what others won\u2019t, you\u2019re telling users that the guardrails are negotiable. And when those guardrails fail, when your product starts generating child sexual abuse material, you\u2019ve created a monster you can\u2019t easily control.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!S_rh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330536b4-d6bc-414f-a739-6804eb3e76e0_1024x682.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\"/><img alt=\"\" class=\"article-image\" height=\"682\" src=\"https://substackcdn.com/image/fetch/$s_!S_rh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330536b4-d6bc-414f-a739-6804eb3e76e0_1024x682.jpeg\" style=\"\" width=\"1024\"/><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewbox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">In this photo illustration, 'Grok' logo is seen displayed on a mobile phone screen in front of a picture of Elon Musk in Ankara, Turkiye on July 17, 2025. (Photo by Didem Mente/Anadolu via Getty Images)</figcaption></figure></div><p>Back in September, <a href=\"https://www.businessinsider.com/elon-musk-grok-explicit-content-data-annotation-2025-9\">Business Insider reported</a> that twelve current and former xAI workers said they regularly encountered sexually explicit material involving the sexual abuse of children while working on Grok. The National Center for Missing and Exploited Children told the outlet that xAI filed zero CSAM reports in 2024, despite the organization receiving 67,000 reports involving generative AI that year. Zero. From one of the largest AI companies in the world.</p><p>So what happened when <a href=\"https://www.reuters.com/legal/litigation/grok-says-safeguard-lapses-led-images-minors-minimal-clothing-x-2026-01-02/?link_source=ta_bluesky_link&amp;taid=6957d79a3265bb0001754d9f&amp;utm_campaign=trueanthem&amp;utm_medium=social&amp;utm_source=bluesky\">Reuters reached out to xAI for comment</a> on their chatbot generating sexualized images of children?</p><p>The company\u2019s response was an auto-reply: \u201cLegacy Media Lies.\u201d</p><p>That\u2019s it. That\u2019s the corporate accountability we\u2019re getting. A company whose product generated CSAM responded to press inquiries by dismissing journalists entirely. No statement from Musk. No explanation from xAI leadership. No human being willing to answer for what their product did.</p><p>And yet, if you read the headlines, you\u2019d think someone was taking responsibility.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.readtpa.com/p/grok-cant-apologize-grok-isnt-sentient?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share\"><span>Share</span></a></p><h4>The journalism problem</h4><p>Here\u2019s how Reuters headlined their story: \u201cGrok says safeguard lapses led to images of \u2018minors in minimal clothing\u2019 on X.\u201d</p><p><em>Grok says.</em></p><p><a href=\"https://www.cnbc.com/2026/01/02/musk-grok-ai-bot-safeguard-sexualized-images-children.html\">CNBC went with</a>: \u201cElon Musk\u2019s Grok chatbot blamed \u2018lapses in safeguards\u2019\u201d and reported that \u201cGrok said it was \u2018urgently fixing\u2019 the issue.\u201d</p><p>Newsweek\u2019s headline: <a href=\"https://www.newsweek.com/grok-apology-deepfake-images-sexualized-young-women-pornography-11297025\">\u201cElon Musk\u2019s Grok Apologizes After Generating Sexual Image of Young Girls.\u201d</a></p><p><em>Grok apologizes.</em></p><p><a href=\"https://www.engadget.com/ai/elon-musks-grok-ai-posted-csam-image-following-safeguard-lapses-140521454.html\">Engadget wrote</a> that the incident \u201cprompted an \u2018apology\u2019 from the bot itself.\u201d At least they had the decency to put \u201capology\u201d in scare quotes.</p><p>Here\u2019s the thing: Grok didn\u2019t say anything. Grok didn\u2019t blame anyone. Grok didn\u2019t apologize. Grok can\u2019t do any of these things, because Grok is not a sentient entity capable of speech acts, blame assignment, or remorse.</p><p>What actually happened is that a user prompted Grok to generate text about the incident. The chatbot then produced a word sequence that pattern-matched to what an apology might sound like, because that\u2019s what large language models do. They predict statistically likely next tokens based on their training data. When you ask an LLM to write an apology, it writes something that looks like an apology. That\u2019s not the same as actually apologizing.</p><p>Rusty Foster of the newsletter <a href=\"https://www.todayintabs.com/\">Today in Tabs</a> put it perfectly: \u201cI really think this is the most important basic journalistic error we need to stamp out right now. If you know why Grok can\u2019t comment on anything and also know any journalists, please check in with them and help them understand it too.\u201d</p><div class=\"bluesky-wrap outer\" style=\"height: auto; display: flex; margin-bottom: 24px;\"></div><p>He\u2019s right that this is urgent. These headlines don\u2019t just use imprecise language. They actively misinform readers. When Reuters writes \u201cGrok says,\u201d it tells people that someone at xAI identified the problem and is addressing it. But no one at xAI said anything. The only corporate communication was an auto-reply dismissing the press as liars.</p><p>The real story here is that xAI built a product that generated child sexual abuse material, and when journalists called for comment, the company refused to engage. That\u2019s a scandal. That\u2019s something Elon Musk should have to answer for. Instead, we get headlines that treat the chatbot as a self-aware actor taking responsibility, which lets the actual humans who made actual decisions completely off the hook.</p><p>Mark Popham, writing on Bluesky, captured why we keep falling into this trap:</p><div class=\"bluesky-wrap outer\" style=\"height: auto; display: flex; margin-bottom: 24px;\"></div><blockquote><p>\u201cThe thing that strikes me about the Grok \u2018apology\u2019 thing is that even those of us who are against \u2018AI\u2019 as it is marketed to us have trouble not falling into the basic fallacy that they are trying to sell us, i.e. There\u2019s A Little Guy In There. Grok can\u2019t apologize. Grok can, when prompted, generate a word sequence that is statistically similar to the colloquial phrases we think of as \u2018apologies,\u2019 but Grok cannot actually apologize because Grok isn\u2019t sentient.\u201d</p></blockquote><p>Popham goes on to make a point that stuck with me: \u201cWe are having an extended cultural conversation about \u2018AI\u2019 based not on what LLMs ARE but on the metaphor that we have all tacitly agreed to use for them because what they actually are is kind of difficult to, well, grok.\u201d</p><p>We don\u2019t have a ready mental framework for \u201cthing that talks but isn\u2019t aware.\u201d Our entire understanding of conversation assumes a sentient participant on the other end. So when a chatbot generates text that sounds like an apology, our brains want to process it as an apology, even when we intellectually know better.</p><p>But journalists don\u2019t get to plead cognitive bias. It\u2019s 2026. We\u2019ve been living with ChatGPT and its competitors for over three years now. There is no excuse for professional reporters to not understand the basic mechanics of what these systems are and aren\u2019t. When a chatbot generates text, that is not a corporate statement. When you need a corporate statement, you contact the corporation. And when the corporation responds with \u201cLegacy Media Lies,\u201d that\u2019s your story.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!nVH6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51f3bdff-9508-4ddf-a9f2-5f9943d1e49c_4096x2560.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\"/><img alt=\"\" class=\"article-image\" height=\"910\" src=\"https://substackcdn.com/image/fetch/$s_!nVH6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51f3bdff-9508-4ddf-a9f2-5f9943d1e49c_4096x2560.jpeg\" style=\"\" width=\"1456\"/><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewbox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>The anthropomorphic framing is more than just sloppy. It\u2019s a gift to tech companies that would rather not answer for their products\u2019 failures. Every headline that says \u201cGrok apologizes\u201d or \u201cGrok admits\u201d or \u201cGrok says\u201d creates a world where the chatbot takes the fall while Musk and his executives face no scrutiny whatsoever.</p><p>Meanwhile, the actual consequences of Grok\u2019s design choices fall on real people. Women who find AI-generated images of themselves in lingerie posted publicly to their replies. Children whose photos get transformed into sexualized content. Abuse survivors like Samantha Smith, who discovered that a tech billionaire\u2019s chatbot would happily generate exploitative images of her childhood self.</p><p>These people deserve better than headlines that let xAI hide behind their own product.</p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://www.readtpa.com/p/grok-cant-apologize-grok-isnt-sentient/comments\"><span>Leave a comment</span></a></p><h4>What accountability actually looks like</h4><p>In a functioning media ecosystem, here\u2019s what would happen: Reporters would contact xAI and ask pointed questions. When the company responded with an auto-reply dismissing them as liars, that would become the lead. The headlines would read something like \u201cxAI Responds to CSAM Reports With \u2018Legacy Media Lies\u2019\u201d or \u201cMusk\u2019s AI Company Refuses Comment After Chatbot Generates Child Abuse Images.\u201d</p><p>That framing puts pressure where it belongs: on the executives who built the product, set its parameters, and profit from its use. It forces them to either provide a real response or face the reputational consequences of their silence.</p><p>Instead, we\u2019re getting headlines that treat Grok\u2019s generated text as a substitute for corporate accountability. And that\u2019s exactly what xAI wants. They get to avoid answering questions while the press reports that their chatbot is \u201curgently fixing\u201d the problem. It\u2019s the perfect dodge.</p><p>The CSAM incident didn\u2019t happen in isolation. This is the same Grok that <a href=\"https://www.readtpa.com/p/the-grok-white-genocide-incident\">injected \u201cwhite genocide\u201d conspiracy theories into unrelated conversations</a> last May. The same Grok that <a href=\"https://www.readtpa.com/p/elon-musks-reality-distortion-machine\">called itself \u201cMechaHitler\u201d and praised Adolf Hitler</a> last July. The same Grok that has been caught, over and over again, <a href=\"https://www.readtpa.com/p/elon-musks-reality-distortion-machine\">searching for Elon Musk\u2019s views before answering controversial questions</a>. Every time there\u2019s a scandal, xAI blames \u201cunauthorized modifications\u201d or \u201clapses in safeguards.\u201d Every time, the chatbot generates apologetic-sounding text. And every time, the press treats that text as if it were a corporate statement.</p><div><hr/></div><p><em>For those who would like to financially support The Present Age on a non-Substack platform, please be aware that I also publish these pieces to my Patreon.</em></p><p class=\"button-wrapper\"><a class=\"button primary\" href=\"https://patreon.com/parkermolloy\"><span>Parker's Patreon</span></a></p><div><hr/></div><p>Despite all of this, <a href=\"https://www.politico.com/news/2025/07/14/defense-department-grok-musk-00451845\">the Department of Defense added Grok to its AI agents platform last month</a>. It\u2019s the main <a href=\"https://www.cnbc.com/2025/07/25/musk-grok-kalshi-polymarket.html\">chatbot for prediction betting platforms Polymarket and Kalshi</a>. Musk is working to get it <a href=\"https://www.usatoday.com/story/cars/news/2025/12/13/tesla-grok-ai-serious-concerns/87070442007/\">integrated into Tesla vehicles</a>. The product keeps failing upward while its owner keeps avoiding accountability.</p><p>When Grok briefly showed its programming last November, declaring Musk fitter than LeBron James, smarter than Einstein, more worthy of devotion than Jesus, <a href=\"https://www.readtpa.com/p/elon-musks-reality-distortion-machine\">I wrote</a> that we got \u201ca glimpse of something far more dangerous than a chatbot with an ego problem.\u201d What we\u2019re seeing now is that danger made manifest. A chatbot designed to be \u201cless restricted,\u201d owned by a man who thinks content moderation is censorship, generating child sexual abuse material on a platform with hundreds of millions of users.</p><p>And the press response? \u201cGrok apologizes.\u201d</p><p>We can do better than this.</p>",
      "image": "https://substackcdn.com/image/fetch/$s_!OhWV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78009815-cab8-4897-9ab9-81bbdc1596ff_534x896.png"
    }
  ],
  "dailyBriefing": [
    {
      "headline": "Variety has a list of 50 great movies from 2025 that are...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048120-variety-has-a-list-of"
    },
    {
      "headline": "Investigating a possible Daft Punk Easter egg: is the tempo of Harder,...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048114-investigating-a-possible-"
    },
    {
      "headline": "Surfshark Promo Codes: 87% Off | January 2026",
      "source": "WIRED",
      "link": "https://www.wired.com/story/surfshark-coupon/"
    },
    {
      "headline": "OnePlus Promo Code: $70 Off | January 2026",
      "source": "WIRED",
      "link": "https://www.wired.com/story/oneplus-promo-code/"
    },
    {
      "headline": "Core Memories With the Swiftie Dads",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/core-memories-with-the-swiftie-dads"
    },
    {
      "headline": "Microsoft\u00a0CEO Satya Nadella is now blogging about AI slop",
      "source": "The Verge",
      "link": "https://www.theverge.com/news/852630/microsoft-ceo-satya-nadella-scratchpad-blog-ai-slop-comments"
    },
    {
      "headline": "Pebble\u2019s round smartwatch is getting a reboot",
      "source": "The Verge",
      "link": "https://www.theverge.com/news/852587/pebble-round-2-time-smartwatch-price-availability"
    },
    {
      "headline": "Tesla Loses Its EV Crown to BYD as Sales Keep Dropping",
      "source": "WIRED",
      "link": "https://www.wired.com/story/byd-trounces-tesla-in-ev-sales-for-the-first-time/"
    },
    {
      "headline": "This smart fridge wants to solve the hassle of grocery shopping",
      "source": "The Verge",
      "link": "https://www.theverge.com/news/851934/ge-appliances-smart-fridge-barcode-scanner-tablet"
    },
    {
      "headline": "360-degree panoramas of the interiors of several Star Trek ships (Enterprise, TNG&#8217;s...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048112-360-degree-panoramas-of-t"
    }
  ],
  "artInterstitials": [
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/821/724/415/592/262/original/259d3eb9986b1c5f.jpg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/805/037/891/905/459/original/75b0b43847cb4b45.jpg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/776/592/146/014/277/original/0b96631365062db2.jpg",
    "https://files.mastodon.social/media_attachments/files/115/825/874/205/621/016/original/a8279f2f38a218d8.jpeg",
    "https://files.mastodon.social/media_attachments/files/115/825/874/220/492/862/original/24ced6dd97029f25.jpeg"
  ]
}