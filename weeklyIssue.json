{
  "meta": {
    "issueNo": "Vol. 2026.1",
    "date": "Sunday, January 04",
    "location": "West Hollywood"
  },
  "coverStory": null,
  "secondaryFeatures": [
    {
      "source": "Things That Caught My Attention",
      "title": "s20e09: An End Of Year Opinion About AI Because Why Not; Good Enough Mitigation of Reasonably Foreseeable Harm",
      "author": "Unknown",
      "bodyText": "<h1>0.0 Context Setting</h1>\n<p>It\u2019s been a minute. This is probably the third draft of an episode that I\u2019ve tried to finish so maybe this one will stick. It has been hard to write, lately!</p>\n<p>It\u2019s December 29 in Portland, Oregon and it is getting cold. Also many things have happened in the world and it feels like things that suck have outweighed the things that don\u2019t suck.</p>\n<hr/>\n<h1>0.1 Some Personal News</h1>\n<p>Hey, did you know I do workshops and coaching now? </p>\n<p>I could explain what they do, but I\u2019ll let someone who\u2019s recently finished the workshop go first and then I\u2019ll come in: </p>\n<blockquote>\n<p>\u201cDan's training is a crash course on how to form direct, empathetic, honest, and strategic relationships with other humans to get hard things done in complicated organizations.\u201d</p>\n</blockquote>\n<p>Huh, that\u2019s pretty good. I would totally try to persuade my company to pay for me to take that workshop. I will go and <a href=\"https://www.verylittlegravitas.com/how-people-work\" target=\"_blank\">read about that workshop series</a> right now.</p>\n<p>That\u2019s for groups of people, though. A bunch of people wanted to know whether they could do it as individuals, and guess what: you can! I\u2019m doing coaching based on the workshop material too, now.</p>\n<p>I am not going to do the thing where you have to email me to find out how much something costs. That is irritating. I will just tell you:</p>\n<ul>\n<li>A 45 minute coaching session is $495 if your company is paying. Your company pays less the more it buys. You should definitely persuade your company to buy a bunch.</li>\n</ul>\n<ul>\n<li>If you\u2019re paying out of pocket, it\u2019s #300 for a session.</li>\n</ul>\n<p>Right now, there are a few spots left with a 15% discount!</p>\n<p>Either way, you should <a href=\"https://calendly.com/verylittlegravitas/how-people-work-getting-started\" target=\"_blank\">book a free sample coaching session</a> so we can have some useful fun together. </p>\n<hr/>\n<h1>1.0 Some Things That Caught My Attention</h1>\n<h2>1.1 An End Of Year Opinion About AI Because Why Not</h2>\n<p>So people are fighting on the internet (well, Bluesky) about LLMs-slash-generative-AI-slash-AI and I\u2019m going to be one of those irritating people who will say \u201cwell, it\u2019s complicated and it depends\u201d.</p>\n<p>One of the reasons why \u201cit\u2019s complicated\u201d and \u201cit depends\u201d is because of the horrific behavior of tech startups and their gold rush land grab intentionally poisoning/collapsing terminology. </p>\n<p>So I\u2019ll just be quick and pretend that we\u2019ve covered that \u201cAI\u201d can mean lots of things, \u201cgenerative AI\u201d is something specific, people are using LLMs for lots of things, some people (maybe not very many, though?) are getting some great results through using specific agentic coding tools (the ones I\u2019m aware about are Simon Willison and Jesse Vincent, who are in and of themselves 10x developers [sic] whether or not they\u2019re using Claude). Then there\u2019s the \u201cAI\u201d machine learning that does stuff like increasing resolution of images but doesn\u2019t go wholesale into generating/filling new details, of which there\u2019s a continuum and grey area anyway.</p>\n<p>ANYWAY.</p>\n<p>One thing that happened was that the American Historical Association puts out guidance<sup id=\"fnref:f1\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:f1\">1</a></sup> that says it\u2019s OK to:</p>\n<ul>\n<li>Ask generative Al to identify or summarize key points in an article before you read it (when you\u2019re not doing explicit citations)</li>\n<li>Use an Al chatbot as a writing partner to help generate and develop ideas (but knowing that you may require explicit citation \u201cdepending on circumstances\u201d)</li>\n<li>Ask generative Al to produce a starter bibliography (when you\u2019re not explicitly citing, but only if you \u201ccheck each reference and additional databases and sources are mined\u201d)</li>\n</ul>\n<p>(very) understandably a lot of people get upset because one of the entire points of being an historian is that you pay a lot of close attention to sources?</p>\n<p>I think there\u2019s clearly a mismatch between people doing the work and people paying for or accepting the work. </p>\n<p>If you\u2019re on the end of someone receiving work, then how much creative thought and insight do you want? How much accuracy do you want? And maybe more importantly, how much are you willing to pay for it? (And then can you be honest about how much you really want, versus how much you say you want? It\u2019s one thing for you to say you want high-quality work, but another to accept work that\u2019s of a lower quality)</p>\n<p>Often I think that the people doing the work can easily care more about and value that work more than the people paying for it. There\u2019s a mismatch between expectations of what a good job, or even a good-enough job is. I can easily see how an academic historian has drilled into them the importance of checking sources and not making sure that anything you\u2019re referencing is factual (or as factual as can be, given your domain of study is history). On the other hand, I can see that managers at a professional organization might be more concerned about <em>output</em> than accuracy.</p>\n<p>For some people, personally, accuracy and correctness matters. I think as a position of principle or temperament. And obviously how much accuracy and correctness matters depends on context. </p>\n<p>So you\u2019ve got someone who wants to do a good job, and you\u2019ve got someone who... doesn\u2019t really care if the job is done that well?</p>\n<p>That\u2019s before you even get into the problem of incremental improvement. Say I can do a job well or I can do a job <em>really</em> well -- is the difference in what I do going to affect an outcome, like the decision someone will make based on my work? Or does it turn out that they weren\u2019t really able to make a different decision anyway? </p>\n<p>(Here\u2019s an abstract example: if your industry goal is to deny 10% of claims, then why work hard on this particular claim to make sure you\u2019re being thorough? Even if you spend more time to make sure you\u2019re doing a good job, <em>ten percent of claims are still going to get denied</em>)</p>\n<p>In that case, why would you care about the accuracy of AI tools if it doesn\u2019t actually make a difference to your boss? If you already felt like what you did didn\u2019t make <em>that</em> much of a difference then I could understand being ground down and just accepting -- well this is just what things are like these days.</p>\n<p>I don\u2019t think bureaucratic processes rely that much on correctness anymore. And I think that the penalties for incorrectness aren\u2019t enough to encourage, well, getting the answer right the first time round. (Another abstract example: the health insurance complex in the U.S. gets a bad rap for healthcare providers sending around erroneous [sic] bills, and if you want to make sure you\u2019re paying for what you actually received then you need to go through your explanation of benefits line by line and then call up, say, the hospital. But the hospital doesn\u2019t get punished for this! There\u2019s no incentive for them to stop doing it. In fact what I suspect happens is that we get even more billing specialists on every side. So that\u2019s good for job growth, I guess?)</p>\n<p>There\u2019s another part, which is that I think modern management practices value data or information over a lack of data or information. Companies would rather have more data -- even if that data is incorrect or has errors -- over no data at all. Why not? I mean, now you\u2019ve got a bit more information with which to make decisions, and don\u2019t you want as much information as possible to make decisions?</p>\n<p>So I think bureaucracies are primed to value more incorrect data over no data at all, and which I think explains this bizarre rush to embrace synthetic data where I shit you not companies are saying well instead of going out and talking to real people and customers we\u2019ll just have the equivalent of ChatGPT tell us what imaginary people think. That\u2019s nuts? I mean, it\u2019s cheaper, sure, but it\u2019s also nuts? I mean today I found out that the U.N. had a program that generated synthetic refugees for people to interact with so that people could understand the plight of refugees. OK, I get the intent. But a lot of refugees and NGOs pointed out that, well, there\u2019s a lot of refugees you could talk to right now? Without having to make anything up?</p>\n<p>Correctness doesn\u2019t matter if the number goes up. Nobody has the time to actually check for causation, so as long as the number goes up <em>and</em> you\u2019re spending a ton of money gathering new data that\u2019s mostly noise, you can\u2019t tell! The AI-generated data or insights must be helping, because your revenue is still going up!</p>\n<p>There\u2019s a side point here where I think that the kind of people in leadership who have no problem mandating the usage of A.I. (let\u2019s say for argument\u2019s sake Bari Weiss, who is Not A Very Good News Editor) are those who have succeeded in fields that don\u2019t require correctness in the first place. </p>\n<p>I\u2019m not even sure if this was a rant. I don\u2019t think there\u2019s necessarily anything to be done about \u201cwhat are we going to do about AI\u201d because the genie is out of the bottle, and all the genie is going to do is follow the economic incentives that already exist. What\u2019s horrifying about it to most people is the scale and speed at which it\u2019s operating, and the scale and speed at which managers and leaders are using to justify their decisions and actions.</p>\n<hr/>\n<p>I do not expect anyone to calm down. The imposition of \u201cAI\u201d absolutely feels like an existential risk what with layoffs and the increasing cost of living in most countries. </p>\n<h2>1.2 Good Enough Mitigation of Reasonably Foreseeable Harm</h2>\n<p>Look, here is another thing about code written by AI. One position is that maybe code doesn\u2019t need to be as correct as it has been in the past, of which: well, that\u2019s a funny opinion. It hasn\u2019t been <em>great</em>, but sure. If code doesn\u2019t need to be as correct as it has been, then it\u2019s totally fine if AI-generated code isn\u2019t as good as human code, right? </p>\n<p>Code just needs to be good enough, and maybe it\u2019s worth it to lower our standards in exchange for volume.</p>\n<p>Good Enough is shorthand and is completely dependent upon context and circumstances. Your good enough is different from my good enough is different from a good enough two weeks ago compared to a good enough two years from now. These things can change!</p>\n<p>Good Enough is important for your stereotypical tech people (or, on reflection, anyone trying to sell anything in today\u2019s world) because you don\u2019t want to spend too much time making something <em>too good</em> otherwise someone else who made something <em>just good enough</em> will beat you to the market and then will steal all the money you thought you\u2019d make. Software people talk about this in terms of not wanting to do any premature optimization because that would slow you down, and if you\u2019re too slow then you don\u2019t move fast enough to break things.</p>\n<p>What are the kinds of things that go into deciding what\u2019s good enough? I think one way of thinking about it is this:</p>\n<p>Good Enough wins because of what you\u2019re able to treat as externalities. </p>\n<p>Here\u2019s some examples:</p>\n<ul>\n<li>Code is \u201cgood enough\u201d because you\u2019re not liable for defects. </li>\n</ul>\n<p>If you <em>were</em> liable for defects then most companies that make software would probably have been sued to oblivion by now and as a result would presumably make software in quite a different way.</p>\n<p>Shitty Silicon Valley VC people who lucked into more money than sense would counter this with: well if we were liable for the products we made then we wouldn\u2019t bother making them and where would you be then? You wouldn\u2019t have an iPhone! Nobody would want to write software because it wouldn\u2019t be worth it! </p>\n<p>I think these people are wrong because that is a stupid position and they are stupid, but either way, we\u2019re not really allowed to find out the opposite case. In England and Wales, for example, it was a matter of law that <em>software is always presumed to be correct</em> and it\u2019s the job of the person who says it isn\u2019t to <em>prove that it isn\u2019t</em>. This reflects a major misunderstanding of how computers work, which is that they do exactly what you tell them to do, and if you tell them to make a mistake then they will absolutely make the correct mistake <em>you</em> told them to make.</p>\n<p>Anyway, good enough as what you\u2019re able to push off onto an externality. More examples!</p>\n<p>Coal-fired power stations are totally good enough to build and operate if you don\u2019t have to care about or pay for people developing lung disease nearby. </p>\n<p>Minimal oversight of mortgage-backed securities is totally fine if you don\u2019t have to care about losing a bunch of money because in the end, you\u2019re too big to fail and a government will bail you out.</p>\n<p>Anything can be personally good enough if the harms or the effects of the harms are distant enough that you\u2019re not affected by them and you don\u2019t see them or care about them.</p>\n<p>An example in government is ministers or secretaries thinking that the services their departments are responsible are <em>totally good enough</em> until you make them try to use them at which point the decent ones are completely horrified that the programs they\u2019re supposed to be responsible for are more or less impossible to use on a practical basis. (That is an exaggeration).</p>\n<p>Carbon-based economies are totally good enough until you\u2019re freezing or baking and millions of people are dying who you actually care about. </p>\n<p>The forces that determine what\u2019s good enough for you include your physical environment and existence. They include the economic context in which you live. They include the government regulations under which you operate, and they include the legal regime in which you operate. </p>\n<p>This entire rant is getting dangerously close to my hobby horse of being able to limit warranties and exclude liabilities for defects in software/technology products. Which is totally a societal decision -- it maps back to the argument I made earlier, where why would you ever bother to do anything if those pesky people could sue you for not doing it right. </p>\n<p>It\u2019s arguable that OpenAI\u2019s ChatGPT has contributed to the death of teenagers by effectively encouraging them to die by suicide. Every week more and more examples come out. </p>\n<p>You would not be surprised that there\u2019s something in ChatGPT\u2019s terms and conditions that effectively says:</p>\n<ul>\n<li>you won\u2019t use this as, like, advice</li>\n<li>don\u2019t trust it</li>\n<li>if you do anything bad as a result of using this, especially if it\u2019s a result of something that this product did that\u2019s bad, then that\u2019s totally not our fault, it\u2019s your fault for using it in the first place</li>\n</ul>\n<p>One of the reasons why I hate this entire thread is because it is giving me flashbacks to undergraduate law and torts and contract law and all that caselaw about whether it\u2019s the manufacturer\u2019s fault that Mrs. Donaghue got sick because there was a decomposed snail in her bottle of ginger beer. This is, like, a seminal case in England and Wales that if I very embarrassingly use Wikipedia to look up (which reminds me of my supervisors being witheringly disappointed in me) established whether a supplier owes a duty of care to prevent a reasonably foreseeable (ha, there it is) harm. </p>\n<p>I MEAN. What sort of harms might be <em>reasonably foreseeable</em> by OpenAI? There\u2019s one particular exclusion in, I don\u2019t know, Microsoft Office, that says you should totally not use Word if you\u2019re operating a nuclear power station and you care about whether there\u2019s a nuclear power accident? I mean, okay?</p>\n<p>What\u2019s particularly galling is that in the case of OpenAI (and a lot of other shitty technology that was deemed <em>good enough</em>) a lot of harm <em>was</em> reasonably foreseeable. </p>\n<p>But that doesn\u2019t matter, does it.</p>\n<hr/>\n<p>So I guess I finished one? Yay. How was your year? </p>\n<p>Best,</p>\n<p>Dan</p>\n<hr/>\n<h2>How you can support Things That Caught My Attention</h2>\n<p>Things That Caught My Attention is a free newsletter, and if you like it and find it useful, please <a href=\"https://newsletter.danhon.com\" target=\"_blank\">consider becoming a paid supporter</a>.</p>\n<h3>Let my boss pay!</h3>\n<p>Do you have an expense account or a training/research materials budget? Let your boss pay, at <a href=\"https://buy.stripe.com/fZe28qbFOazZ4M04gh\" target=\"_blank\">$25/month, or $270/year</a>, <a href=\"https://buy.stripe.com/cN200i8tCgYn4M0eUW\" target=\"_blank\">$35/month, or $380/year</a>, or <a href=\"https://buy.stripe.com/bIYcN4cJSgYnbao9AD\" target=\"_blank\">$50/month, or $500/year</a>.</p>\n<p>Paid supporters get a free copy of <a href=\"https://store.verylittlegravitas.com/l/ThingsVol1\" target=\"_blank\">Things That Caught My Attention, Volume 1</a>, collecting the best essays from the first 50 episodes, and <a href=\"https://verylittlegravitas.gumroad.com/l/ThingsVol1/subscriber\" target=\"_blank\">free subscribers get a 20% discount</a>.</p>\n<div class=\"footnote\">\n<hr/>\n<ol>\n<li id=\"fn:f1\">\n<p><a href=\"https://www.historians.org/resource/guiding-principles-for-artificial-intelligence-in-history-education/\" target=\"_blank\">Guiding Principles for Artificial Intelligence in History Education</a>, American Historical Association, 5 August 2025 (<a href=\"http://archive.is/latest/https://www.historians.org/resource/guiding-principles-for-artificial-intelligence-in-history-education/\" target=\"_blank\">archive.is</a>)\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:f1\" title=\"Jump back to footnote 1 in the text\">\u21a9</a></p>\n</li>\n</ol>\n</div>",
      "image": "https://placehold.co/800x600/111/333?text=No+Image"
    }
  ],
  "dailyBriefing": [
    {
      "headline": "Evergreen: No Blood For Oil vs. Exactly How Much Oil Are We...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048121-evergreen-no-blood-for-oi"
    },
    {
      "headline": "Core Memories With the Swiftie Dads",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/core-memories-with-the-swiftie-dads"
    },
    {
      "headline": "Bose Promo Code: 40% Off Bose for January 2026",
      "source": "WIRED",
      "link": "https://www.wired.com/story/bose-coupon-code/"
    },
    {
      "headline": "Surprise, surprise: Silksong wins Steam\u2019s Game of the Year",
      "source": "The Verge",
      "link": "https://www.theverge.com/games/853786/hollow-knight-silksong-steamawards-game-of-the-year"
    },
    {
      "headline": "This smart home controller is literally a piece of wood",
      "source": "The Verge",
      "link": "https://www.theverge.com/tech/852598/mui-board-smart-home-controller-matter"
    },
    {
      "headline": "Hulu Promo Codes & Discounts: 20% Off January",
      "source": "WIRED",
      "link": "https://www.wired.com/story/hulu-promo-code/"
    },
    {
      "headline": "Hydrow Discount Code: Save Up to $150 | January 2026",
      "source": "WIRED",
      "link": "https://www.wired.com/story/hydrow-discount-code/"
    },
    {
      "headline": "Investigating a possible Daft Punk Easter egg: is the tempo of Harder,...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048114-investigating-a-possible-"
    },
    {
      "headline": "I went to the Stranger Things finale in theaters and the strangest thing happened",
      "source": "The Verge",
      "link": "https://www.theverge.com/streaming/853133/stranger-things-finale-theater-scene-report"
    },
    {
      "headline": "eBay Coupon Codes and Deals: Up to 60% Off Select Items",
      "source": "WIRED",
      "link": "https://www.wired.com/story/ebay-coupon-code/"
    }
  ],
  "artInterstitials": [
    "https://files.mastodon.social/media_attachments/files/115/825/874/205/621/016/original/a8279f2f38a218d8.jpeg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/776/592/146/014/277/original/0b96631365062db2.jpg",
    "https://files.mastodon.social/media_attachments/files/115/825/874/220/492/862/original/24ced6dd97029f25.jpeg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/805/037/891/905/459/original/75b0b43847cb4b45.jpg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/821/724/415/592/262/original/259d3eb9986b1c5f.jpg"
  ]
}