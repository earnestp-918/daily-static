{
  "meta": {
    "issueNo": "Vol. 2026.3",
    "date": "Friday, January 16",
    "location": "West Hollywood"
  },
  "coverStory": null,
  "secondaryFeatures": [
    {
      "source": "Weekly Newsletter \u2013 Jim Louderback",
      "title": "Creepy 2026 Signals and 1BFS Takeaways",
      "author": "Jim",
      "bodyText": "<p><strong>This Week: </strong>You can\u2019t predict the future without watching the creepy signals that might turn into megatrends. So, I\u2019m sharing my top 10 weird ones to monitor.\u00a0 Also, I just spent 10 days on-site in Dubai producing the 1 Billion Followers Summit. The rest of this issue includes highlights and what I learned.</p>\n<p>Hi, I\u2019m <strong>Jim Louderback</strong> and this is my weekly creator economy newsletter. If you\u2019ve received it, then you are either subscribed or someone forwarded it to you.\u2028</p>\n<p>If the latter \u2013 and you want to subscribe, <a href=\"https://insidethecreator.beehiiv.com/subscribe\">get it here</a>!</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\">TEN CREEPY SIGNALS TO MONITOR</h2>\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img alt=\"\" class=\"article-image\" height=\"227\" src=\"https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/image-1.png?resize=204%2C227&amp;ssl=1\" style=\"\" width=\"204\"/></figure></div>\n<h3 class=\"wp-block-heading\">AI Is Coming for Your Ears</h3>\n<p>AI-generated podcasts will steal meaningful market share from human creators over the next few years. Google\u2019s NotebookLM helped kick this off, but now top creators, startups, and established media companies are leaning in.</p>\n<p>Inception Point AI, for example, says it has produced 200,000 episodes, claiming that at times its shows accounted for 1% of all podcasts released in a given week. Steven Bartlett is using AI to create more content for his podcast fans. And The Washington Post is creating \u201cYour Personal Podcast\u201d to build podcasts tailored to each user\u2019s profile.</p>\n<p>These experiments are roundly criticized by traditional media, but they aren\u2019t going away. More from <a href=\"https://www.npr.org/2025/12/13/nx-s1-5641047/washington-posts-ai-podcast\">NPR</a> and the <a href=\"https://www.latimes.com/business/story/2025-12-12/ai-podcasting-is-changing-industry\">LA Times</a>.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img alt=\"\" class=\"article-image\" height=\"223\" src=\"https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/image-2.png?resize=206%2C223&amp;ssl=1\" style=\"\" width=\"206\"/></figure></div>\n<h3 class=\"wp-block-heading\">The Rise of Biometric Algorithms</h3>\n<p>Social algorithms will start incorporating data from health trackers to deliver even more targeted recommendations, and more insidious ways to addict us to the feed.</p>\n<p>We\u2019ll move beyond time-spent and click-throughs to heart-rate spikes and pupillary dilation. Some platforms may even push bio-integration to deliver interruption-free content (and yes, this could be how Western microdramas monetize).</p>\n<p>The consequences are wide-ranging:</p>\n<ul class=\"wp-block-list\">\n<li>Creators optimize for physical response, not just retention.</li>\n<li>\u201cPhysiological editing\u201d becomes a thing.</li>\n<li>Iron-clad vendor lock-in.</li>\n</ul>\n<p>Also, your body will betray you. Your \u201cI want educational podcasts\u201d goal will get steamrolled by biomarker evidence that you prefer rage-bait and AI slop.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img alt=\"\" class=\"article-image\" height=\"212\" src=\"https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/image-3.png?resize=205%2C212&amp;ssl=1\" style=\"\" width=\"205\"/></figure></div>\n<h3 class=\"wp-block-heading\">From NPC to PC \u2013 the Rise of the Playable Creator</h3>\n<p>Back in 2004, we typed commands to a guy in a chicken suit (Subservient Chicken) and laughed because it gave us the illusion of control.</p>\n<p>Twenty-two years later, the chickens have come home to roost.</p>\n<p>Creators are starting to turn their lives into fan-controlled characters where it\u2019s not just \u201cdo a thing,\u201d but binding decisions, both mundane and macro, selected and paid for by doting fans. What to eat. When to sleep. Who to date.</p>\n<p>Fans will even control a creator\u2019s environment: thermostat, lighting, alarm clock, smartwatch. Creators who embrace this will outsource decision-making to their audience. Fans will relish controlling something, anything, in our topsy-turvy world.</p>\n<p>This voluntary dehumanization gives us Truman Show 2.0, where Truman is begging for donations and the audience is the director.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img alt=\"\" class=\"article-image\" height=\"205\" src=\"https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/image-4.png?resize=204%2C205&amp;ssl=1\" style=\"\" width=\"204\"/></figure></div>\n<h3 class=\"wp-block-heading\"><strong>Verification Vlogging</strong></h3>\n<p>Flesh and blood creators will increasingly opt for ways to prove they are human, not AI constructs<strong>. </strong>From the \u201cPlayable Creator\u201d to live streamed and IRL appearances, human markers explode.</p>\n<p>One creepy format that\u2019s already emerging is boredom content: creators sleeping, eating messy food, stumbling over words, and even sprinkling grammatical and spelling errors into their newsletters (some creators are already doing this\u2026 wink-wink).</p>\n<p>The world increasingly bifurcates:</p>\n<ul class=\"wp-block-list\">\n<li>Scalable, synthetic and corporate owned perfection.</li>\n<li>Messy, gross and error-prone humans.</li>\n</ul>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img alt=\"\" class=\"article-image\" height=\"194\" src=\"https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/image-5.png?resize=192%2C194&amp;ssl=1\" style=\"\" width=\"192\"/></figure></div>\n<h3 class=\"wp-block-heading\">Life as a service</h3>\n<p>In 2026 and beyond, creators will realize their body and their voice are an asset class.</p>\n<p>Mid-tier creators will start licensing their deepfake rights so they can \u201cwork\u201d in multiple places at once. Brands will use recognizable creator likenesses as customer support reps, virtual store clerks, and region-specific ad characters.</p>\n<p>Voice becomes its own asset class too, as more companies follow ElevenLabs by licensing a creator\u2019s voice for separate AI avatars. When identity decouples from the physical person, creators become IP holding companies.</p>\n<p>The good news: it becomes easier to sell a channel.</p>\n<p>The downside: it multiplies key-person risk. What happens when your avatar goes off the rails and starts spewing racist or illegal nonsense?</p>\n<ul class=\"wp-block-list\">\n<li><strong>Related</strong>: Creators will sell customized AI versions of themselves to superfans, and platforms will try to muscle in on the revenue.</li>\n<li><strong>Related</strong>: Taken to its macabre extreme, we\u2019ll see creators \u201clive\u201d long beyond their lifespan. But who owns these forever identities, and how do you value them? We\u2019ll find out.</li>\n</ul>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\"><strong>BONUS \u2013 FIVE MORE SIGNALS I\u2019M TRACKING</strong></h2>\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><img alt=\"\" class=\"article-image\" height=\"138\" src=\"https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/5-signals-Small.jpg?resize=560%2C138&amp;ssl=1\" style=\"\" width=\"560\"/></figure></div>\n<p><strong>Affiliate Links Vaporize: </strong>AI agents discover, bid, and buy products for consumers. When that happens, affiliate links get bypassed. It will be gradual, but it could rewrite purchase influence.</p>\n<p><strong>Scammer Crack-Down:</strong> The FTC and other watchdogs get serious about deepfake scams. Criminals stay two steps ahead, but enforcement improves.</p>\n<p><strong>The Rise of the Ozempic Creator</strong>: As GLP-1 weight loss drugs go mainstream the \u201cabundance aesthetic\u201d fades.\u00a0 Oprah is just the beginning Expect more precision nutrition, bio-compatible recipes, and chemically altered lifestyle content.</p>\n<p><strong>The Nose Knows:</strong> Olfactory computing tries to leave the lab. Again. Algorithmically triggered smells could become the next big creator-led revolution.\u00a0 Or not.</p>\n<p><strong>Who Are You?\u00a0 </strong>Better age and identity verification spreads. Pair that with global crackdowns on teens and social media, and you get new restrictions and new creator opportunities.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\"><em>SPONSOR</em></h2>\n<p>LinkedIn\u2019s <a href=\"https://business.linkedin.com/marketing-solutions/b2b-institute/easy-to-find-being-where-b2b-buying-happens\">new B2B Buyer Report</a> makes the case better than I ever could: buyers trust expert voices more than brands, and they spend most of their research time reading the people who actually understand the space. That\u2019s exactly my audience: marketers, media execs, founders, top creators and operators who shape budgets and make decisions.\u00a0</p>\n<p>A weekly sponsorship puts your company inside a trusted, high-intent environment, shows up repeatedly where it actually matters, and aligns your brand with the point-of-view content buyers say moves them. If you want to speak to the people building the next wave of media, creators, and AI, this is where they show up every week.<strong>\u00a0</strong></p>\n<p>Drop me an <a href=\"mailto:jim@louderback.com\">email</a> and <a href=\"https://docs.google.com/document/d/19ScSYOFx3aV0eKfKqqqA-JxV-ibrNbhufuNE2NbYFJk/edit?tab=t.0\">check out our sponsorship information here.</a></p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\">1BFS  RECAP</h2>\n<p>The 1 Billion Followers Summit was a magical and amazing gathering of creators, execs, investors and platforms from around the world.\u00a0 My Economy track featured 120 speakers and 55 sessions across four stages, focusing on what\u2019s happening now, and what the future holds.\u00a0</p>\n<p>Some key takeaways:</p>\n<h3 class=\"wp-block-heading\"><strong>CREATORS AND REPRESENTATION</strong></h3>\n<p>CAA top exec @Brent Weinstein and I sat down for a fireside chat exploring the new CAA Creators, where the industry is going and more.\u00a0 Here\u2019s what I learned:</p>\n<ul class=\"wp-block-list\">\n<li><strong>Podcasting as Training Wheels:</strong> Traditional celebs have tried to enter the creator space with decidedly uneven results.\u00a0 Podcasting gives them a back door that makes the shift so much easier.\u00a0</li>\n<li><strong>Who\u2019s Afraid of the Big Bad Slop:</strong> Not Brent\u00a0</li>\n<li><strong>Sports Rises:</strong> Creators are embracing sports, and athletes are emerging as a powerful creator class. Huge growth area.</li>\n</ul>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h3 class=\"wp-block-heading\"><strong>LINKEDIN CHANGES AHEAD</strong></h3>\n<p>I talked with LinkedIn\u2019s head of creator product @Sam Carrao Clanon to get a peek into the future of the B2B platform.\u00a0 Key insights:</p>\n<ul class=\"wp-block-list\">\n<li><strong>Analytics:</strong>\u00a0 LinkedIn knows creators need better data, and they can\u2019t do everything. Expect better analytics this year. He also hinted an open API might be on the horizon.</li>\n<li><strong>To Video or Not to Video:\u00a0 </strong>Exaggerating for effect, Clanon said you should either do all video or none. My take: make video your primary focus, or keep it as an occasional dabble.</li>\n<li><strong>Optimal Post Frequency</strong>:\u00a0 3-5 times a week</li>\n<li><strong>He\u2019s Killing the \u201cFormula\u201d </strong>:\u00a0 The tired post format of hook, personal story, bulleted list and call to action will be de-prioritized.\u00a0 Clanon wants all types of posts, from one-liners to deep insight, to thrive on LinkedIn.</li>\n<li><strong>Pods</strong>: LinkedIn sounds serious about de-emphasizing pods, too.</li>\n</ul>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h3 class=\"wp-block-heading\"><strong>INSDE THE BELLY OF THE BEAST</strong></h3>\n<p>I also had a chance to chat with Mr Beast\u2019s head of channel @Will Fowler, and his commercial counterpart @Beau Avril about how commerce and creative collaborate on Beast videos.\u00a0\u00a0</p>\n<p><strong>Treat Integrations as Content:</strong> Brand deals are part of the story arc, not a sponsorship interrupt. Brands get pulled in early, but integrations must elevate the episode and protect retention. Best examples (Starbucks in \u201c30 Days in the Sky,\u201d DoorDash in \u201c100 Days on a Jet\u201d) work because the brand solves a real problem aligned with the premise. Also, it helps that Jimmy genuinely gets excited about brand partners.</p>\n<p><strong>Ideas Come from Anywhere</strong>: Often via a 3 a.m. call from Jimmy. They quickly vet concepts via title and thumbnail development, then move into a hard feasibility phase that weighs timeline, build complexity, and even whether the science exists to support the premise (90 Days in Space, for example, requires SpaceX to step up).</p>\n<p><strong>Time Rules:</strong> Shoots can run 30\u2013100 days, with teams filming nearly nonstop. Roughly four episodes are in production at any time, scaling to seven soon, which likely means external help.</p>\n<p><strong>Strong Advice</strong>: Creators should explain their audience\u2019s unique value to brands. Brands should stop over-engineering and trust creators to keep them native to the story.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h3 class=\"wp-block-heading\">SUPERFANS BEAT FOLLOWERS\u00a0</h3>\n<p>I loved the discussion with @Abby Ho, @Sara Wilson, and @Jo Burford about the move from scale to trust.</p>\n<p>They argued we\u2019ve shifted from the social graph to an AI-driven interest graph, where having a million followers doesn\u2019t mean a million people see you. I\u2019d take it one step further: AI is pushing us from the interest graph to the trust graph, meaning who we trust and where and how to we connect.</p>\n<p>Followers are losing power as a metric. Distribution is becoming identity-based relevance. Sharing happens more in DMs and private groups than public feeds. But these niche groups aren\u2019t necessarily small.\u00a0 Instead, they are focused and specific.</p>\n<p>Best advice? Design your content and brand messaging for the \u201cOMG that\u2019s so me\u201d moment and you\u2019ll have a fan for life.\u00a0 \u00a0Stop marketing to communities and start building with them. The real risk isn\u2019t being too niche. It\u2019s being culturally irrelevant at scale.</p>\n<p>They also nailed the fandom trap: Show up late with slow activations, then show up wrong by not speaking the language. And beware overfeeding fandoms until they fatten up into manufactured affinity.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\">1BFS QUIBIS</h2>\n<p><strong>The \u201cCurse of Knowledge\u201d:</strong> Many creators fail to monetize because they assume everyone knows what they know. @Justin Mecham, founder of Creatyl, said what feels \u201cbasic\u201d to a creator often feels like \u201cmagic\u201d or \u201cwizardry\u201d to the audience.</p>\n<p><strong>LinkedIn\u2019s Content Deficit</strong>: @Vin Matano, CEO of CreatorBuzz shared that despite having over 1 billion users, only 1% of LinkedIn users create content, making it a massive \u201ccontent-deficient\u201d opportunity for influence and credibility.</p>\n<p><strong>The \u201c11th Episode\u201d Benchmark:</strong> In podcasting, explained Gautam Raj Anand, founder and CEO of Hubhopper, reaching the 11th episode puts a creator in the top 1% of podcasters globally due to the high rate of \u201cpodfading\u201d (quitting early).</p>\n<p><strong>On Audio</strong>: \u201cFood without taste is the equivalent of content without audio\u2026 video without audio and music is like empty calories.\u201d \u2014 @<em>Oscar H\u00f6glund, CEO of Epidemic Sound</em>.</p>\n<p><strong>On Branding:</strong> \u201cTrends are containers. They\u2019re not really the idea\u2026 The more you jump on trends, the less distinctive you will look.\u201d \u2014 @<em>Sara Zouad, CEO of Brand Builders</em>.</p>\n<p><strong>On Monetization</strong>: \u201cAs a creator, if you\u2019re solving people\u2019s problems, it\u2019s okay to make money\u2026 If you\u2019re not making crazy money as a creator, it\u2019s a hobby.\u201d \u2014 @<em>Justin Mecham, Founder of Creatyl</em>.</p>\n<p><strong>On Business Ownership:</strong> \u201cControl equals freedom. If you maintain control of your business at all times, you will always have the option of how you want to live.\u201d \u2014 <em>Tobi Oluwole, Founder of Magnate</em>.</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\">OTHER 1BFS HOT TAKES</h2>\n<p><strong>Living the Fizz:</strong> @Sara Wilson shares her top 7 takeaways from 1BFS.\u00a0 She\u2019s spot on.\u00a0 (<a href=\"https://communitycatalysts.substack.com/p/7-patterns-from-dubai-that-should\">Community Catalysts</a>)</p>\n<p><strong>Trust Rules:</strong> @Robb Montgomery with journalism-tinged takeaways. (<a href=\"https://robbmontgomery.com/content-for-good-my-takeaways-from-dubais-1-billion-followers-summit/\">RobbMontgomery</a>)</p>\n<p><strong>It\u2019s Just a Start: </strong>@David Adeleke with an African creator look at 1BFS. (<a href=\"https://www.readcommunique.com/p/notes-from-1-billion-followers-summit-dubai\">Communique</a>)</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<h2 class=\"wp-block-heading\">CREATOR ECONOMY QUIBIS\u00a0</h2>\n<p>Short section this week, we\u2019ll be back on news analysis next week!</p>\n<p><strong>Meta Abandons VR:</strong>\u00a0 1000+ to be laid off from \u201cReality Labs\u201d.\u00a0 (<a href=\"https://www.engadget.com/ar-vr/meta-refocuses-on-ai-hardware-as-metaverse-layoffs-begin-145924706.html\">eWeek</a>)</p>\n<p><strong>Apple Discovers Creators:\u00a0 </strong>Launches a new $13 monthly creator bundle with Final Cut Pro, PIxelmator Pro, LogicPro and more<strong> (</strong><a href=\"https://9to5mac.com/2026/01/13/apple-announces-pixelmator-pro-is-coming-to-ipad/\"><strong>9to5Mac</strong></a><strong>)</strong></p>\n<p><strong>Microdrama Formats Expand: </strong>Lots of talk on the topic at 1BFS, now @Scott Brown is working on a musical using the Microdrama framework.\u00a0 Can\u2019t wait to see it (<a href=\"https://www.msn.com/en-us/tv/news/hannah-stocking-amber-laird-sophie-sumner-star-in-playback-billed-as-first-musical-microdrama/ar-AA1TKVBY\">MSN</a>)</p>\n<p><strong>Discord Will IPO:</strong> Been a long time coming, but the social community app looks to cash out.\u00a0 Wonder if it will surpass the $10B Microsoft offered back in 2021?\u00a0 (<a href=\"https://techcrunch.com/2026/01/07/discords-ipo-could-happen-in-march/\">TC</a>)</p>\n<p><strong>Saving Media:</strong>\u00a0 Doug Shapiro drops his 2026 presentation on the next disruption and what to do about it.\u00a0 (<a href=\"https://dougshapiro.substack.com/p/my-base-presentation-deck-january\">The Mediator</a>)</p>\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n<p><strong>Where\u2019s Jim?\u00a0 </strong>Flying home to San Francisco as I write this.\u00a0 Been gone for almost two weeks.\u00a0 Not going anywhere for a little while!\u00a0 Oh and the lack of robust WiFi on Emirates means I\u2019m not publishing until Wednesday.\u00a0\u00a0</p>\n<p>Like this free newsletter?\u00a0 <a href=\"https://www.buymeacoffee.com/jlouderb\">Buy me a coffee</a> and say thanks!\u00a0 Or let\u2019s do a meetup in your town.</p>\n<p>100% written by me.\u00a0 AI used very sparingly for edits.</p>\n<p>I\u2019ve built and sold multiple creator economy startups to top media companies \u2013 including an MCN to Discovery and VidCon to Paramount. <a href=\"https://www.linkedin.com/build-relation/newsletter-follow/?entityUrn=6762441989427478528\">Subscribe here on LinkedIn</a> to get this newsletter every Monday.</p>\n<p>Let me know what you think \u2013 email me at <a href=\"mailto:jim@louderback.com\">jim@louderback.com</a>. Thanks for reading and see you around the internet.\u00a0</p>",
      "image": "https://i0.wp.com/louderback.com/wp-content/uploads/2026/01/image-1.png?resize=204%2C227&ssl=1"
    },
    {
      "source": "Things That Caught My Attention",
      "title": "s21e03: The Problem is Defining the Problem; The Unreasonable Effectiveness of Caring",
      "author": "Unknown",
      "bodyText": "<h1>0.0 Context Setting</h1>\n<p>I am sneakily writing this on Wednesday, January 14, 2026 in Portland Oregon, where I just finished writing the previous episode. </p>\n<p>It is taking <em>a lot</em> of energy to deal with my impulse control to post this straight away, and what I\u2019m going to do instead is schedule it for Thursday, just to annoy Pavel and beat his issue of The Product Picnic<sup id=\"fnref:picnic\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:picnic\">1</a></sup>. </p>\n<h1>1.1 The Problem is Defining the Problem</h1>\n<p>I\u2019m not, personally, worried too much about AI completely devastating my work. I may be completely misplaced in this assumption, though.</p>\n<p>There\u2019s a big fight going on about the usage of AI in developing software. There\u2019s a big continuum here! </p>\n<p>On one end you have my friends Jesse Vincent and Simon Willison, who are more or less forging ahead at using agentic coding (i.e. LLMs for writing software, commonly Claude Code) to become even more irritatingly productive than they already are, a sort of Captain America-serum supercharged already-10x developer.</p>\n<p>The thing is, you have to be so precise about what someone is using generative AI for these days because as a recent saying goes, AI progress and capability is <em>jagged</em>, which is another way of saying \u201call over the heckin\u2019 place\u201d. They can do some things really well, and are stunningly bad at other things (those other things include stuff like \u201chow many rs are there in the word irresponsible\u201d).</p>\n<p>If you recognize that you\u2019ve got a tool with wildly different capability in different domains, then you also recognize that you have a capricious tool and you need to know what you\u2019re doing to not shoot yourself in your foot or deglove yourself or whatever. (Don\u2019t look up degloving if you don\u2019t know what it is, trust me.)</p>\n<p>Simon and Jesse are experts with decades of software development knowledge. I also understand them to be systems thinkers - they know enough about how everything works. In temperament as well, they\u2019re curious but also untrusting. Not everyone is like them. The point here is that the tools aren\u2019t easy to use well, where \u201cwell\u201d means producing software that meets certain criteria. What Simon and Jesse are also good at is deciding what those criteria are in ways that are appropriate to the task and context. This is also something that not everyone is good at. </p>\n<p>I think \u201cdeciding what well is\u201d is an inherently human skill that is very difficult for AI to replicate well enough consistently.</p>\n<p>Iris Meredith wrote this piece that Kevin Wriggle quoted<sup id=\"fnref:quoted\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:quoted\">2</a></sup>:</p>\n<blockquote>\n<p>More generally, what I got from this is that LLM-assisted coding is only more flexible and more chill than doing the thing manually if you don't care about results at all. The moment you start caring about a specific output rather than something vaguely output-shaped, it all of a sudden becomes a whole lot more rigid and finicky than just writing the thing manually. And that's quite the opposite of what LLM assistants promise.<sup id=\"fnref2:iris\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:iris\">3</a></sup></p>\n</blockquote>\n<p>In case it\u2019s not clear, the jaggedness and unevenness of the tools means that I disagree with Meredith, to a degree. I\u2019ll rewrite with emphasis in a way that I hope doesn\u2019t invalidate Meredith\u2019s point:</p>\n<blockquote>\n<p>More generally, what I got from this is that LLM-assisted coding is only more flexible and more chill than doing the thing manually if you don't care about results at all. The moment you start caring about a specific output rather than something vaguely output-shaped, it all of a sudden becomes a whole lot more rigid and finicky than <strong>you</strong> just writing the thing manually. And that's quite the opposite of what LLM assistants promise.<sup id=\"fnref:iris\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:iris\">3</a></sup></p>\n</blockquote>\n<p>I think the point here is that agentic coding/LLM-assisted coding (and therefore I think all LLM tools <em>in general</em>) is that <strong>they are not general purpose tools</strong>. Or, rather, the domains in which they are general purpose tools that are <em>good enough</em> for people are also uneven, but that\u2019s not exposed when you\u2019re \u201cusing ChatGPT\u201d. This problem is also obscured (intentionally?) by the chat-based interface, which provides no real indication or feedback about the specific things the LLM is good at -- there are no task-specific UIs for general agents. </p>\n<p>I think what Simon and Jesse have done is to massively customize the tools for their own particular usage. That\u2019s on a different end of the continuum of using LLM-assisted coding out of the box. <em>They just aren\u2019t ready for mass use yet</em>.</p>\n<p>This is not a criticism, in any way, of Meredith\u2019s capability or experience. And at the same time maybe the insight isn\u2019t particularly deep and it\u2019s just that I came about it another way: if you don\u2019t know how to use a tool, then you won\u2019t use it well and you won\u2019t know when you\u2019re using it dangerously. I\u2019m quite happy to place irresponsibility here on the lawn of the product marketers, who <em>are</em> presenting these as general purpose products. I\u2019ve written before about how egregiously irresponsible OpenAI is in hiding what you shouldn\u2019t use ChatGPT for in fine print, (in a filing cabinet, disused toilet, basement, beware of leopard etc) in its terms and conditions of usage. Bullshit, I say.</p>\n<p>So I think I disagree as to the utility of LLM-assisted coding agents in that finicky lawyerly way of \u201cokay, but here are the instances in which they\u2019re clearly useful and some people are clearly deriving benefit\u201d. </p>\n<p>I will lay aside (yes, I know), the immoral manner in which the data for these agents has been gathered/stolen/appropriated under a political and regulatory environment that outright encourages such stealing and also now that it\u2019s happened wishes to preserve those interests \u201cOh no, we\u2019ll go bankrupt if we have to compensate artists\u201d and \u201cwell we couldn\u2019t possibly let that happen\u201d. I will acknowledge that yes, we have legislated to stop doing things before, in the face of incredibly powerful lobbying, when indoor smoking was banned and that yes of course we can just do things.</p>\n<p>Anyway, I digress, but also do not intend to dismiss a stupendously big societal elephant in the room.</p>\n<p>Meredith wrote about <em>caring about a specific output, rather than something vaguely output-shaped</em> which is not an LLM-problem (which Meredith makes clear) but a human problem. Humans -- people -- are the ones who ultimately set goals. <em>There is nothing else in our entire experience right now that can do this</em>. I mean we could decide that dolphins are sentient and collaborate with them to set goals, but like I said \u201c<em>in our entire experience right now\u201d</em>. In that same conversation with Riggle, Riggle said:</p>\n<blockquote>\n<p>As I keep saying, human understanding will always matter</p>\n</blockquote>\n<p>and to which I said:</p>\n<blockquote>\n<p>To the extent that we exist and tools don\u2019t exist in a vacuum, yeah! There is no no-human-in-the-loop, it\u2019s like some sort of anthropic principle for technology.</p>\n</blockquote>\n<p>The argument, again, here is that technology inherently has a bias because humans have a bias and like the theory of the anthropic principle (the universe only exists because we are here to exist, may as well call it the eogist principle), <em>technology and tools don\u2019t exist without people</em>.</p>\n<p>The first mover is always a human: a human aways, always, <strong>always</strong> started it.</p>\n<p>What I mean here is that we define goals, which in this case means what the software is supposed to do, which means we define outcomes. We define and set the parameters of the outcomes. Like I\u2019ve written before, those parameters define what\u2019s good enough, what trade-offs exist because everything is a trade-off. Everything is a negotiation of what you will accept, and in software development that\u2019s normally boiled down to fast/cheap/correct, and you can only realistically pick one. </p>\n<p>The problem is that figuring out what we want is one of the hardest things in the world, and I don\u2019t just mean in the personal \u201cwhat is the point of my life\u201d sense. There is always more detail. There are always more edge cases because the universe goes on. On one level you can say because of entropy, on another level you can say it\u2019s because you don\u2019t control everything, on one more level you can say it\u2019s because humans are batshit crazy and will come up with a whole bunch of ways to do things that you never conceived of which, to be fair, is one of the strengths that got us here in the first place.</p>\n<p>Now, <em>one</em> way that we invented to deal with the \u201cwe don\u2019t know what we want\u201d problem in software development is this whole agile development process. Which as a refresher is roughly along these lines:</p>\n<ul>\n<li>we don\u2019t know what we want</li>\n<li>but if we\u2019re given something, we can provide feedback on it (I don\u2019t want <em>that, why did you do that?!</em>)</li>\n<li>we can take that feedback and then change the thing</li>\n<li>repeat until the heat death of the universe</li>\n</ul>\n<p>What this ultimately emphasizes is that a practice of iteration/repetition allows the possibility of improvement. </p>\n<p>I was very careful there to say <em>the possibility</em> of improvement, because humans in general are lazy which is totally fine and not a value judgment, and when we\u2019re lazy we tend to skip steps and think that iteration/repetition <em>automatically leads to improvement</em>. Which it doesn\u2019t, not if you put it that way.</p>\n<p>When I work with people and we really slow down then I\u2019ll ask: well, what improvement are we looking for?</p>\n<p>And invariably people get a bit stumped there. One common reaction (but a minority, to be clear) is a bit of anger and lashing out because they think they should know the answer and isn\u2019t there an obvious answer. The reason why they\u2019re angry is that there isn\u2019t a good (sorry, a <strong>useful</strong>) answer.</p>\n<p>My pithy version of this insight [sic] that I use in my work is to rephrase as:</p>\n<blockquote>\n<p>Agile is a great way to do the wrong thing faster</p>\n</blockquote>\n<p>which a) sticks in peoples\u2019 minds because it\u2019s pithy and I guess mean? and b) is an opening for a bunch of people to admit that nobody (or leadership) knows what it is they\u2019re supposed to be doing here in the first place in useful detail.</p>\n<p>Agentic coding -- using LLMs to write code -- is certainly a way to write more code more quickly. The argument I\u2019m piecing together supported by Meredith is that writing more code more quickly is useless (or even worse, actively harmful) towards achieving your desired outcome.</p>\n<p>You achieve what you want by being able to define what you want. Defining what you want is <em>hard</em>. In the language of AI researchers, defining your problem is something that nothing, nobody, not ever can ever one-shot (i.e. get right first time) because part of defining what you want involves almost limitless context to determine what\u2019s good enough and hoping that matches up with what <em>you</em> think is good enough, dealing with the difference between the two, and then a human <em>making a decision</em>.</p>\n<p>Many people don\u2019t, in general, like making decisions because they might be wrong and then they are shouted at by mean people. This is a genuine problem holding us back as a society, I am being absolutely sincere.</p>\n<p>I concede that LLMs might be able to produce a range of good-enoughs. I see this with Claude Code when it\u2019s in planning mode and I explicitly ask it to provide me options with different trade-offs and then explore those trade-offs so I can think about them. I don\u2019t want <em>the one thing to do</em>. Or rather, there are cases where I know enough that I don\u2019t want the one thing to do. There\u2019s an argument here that at one level the implementation of software doesn\u2019t fundamentally matter and your choices are more a matter of taste, and that in different areas the architecture and implementation do have a much more significant impact. Knowing that comes with experience, or at least something that has access to experience. We used to also call these things expert systems, but it turns out the lazier way to do that was to just throw the entire internet at them and assume that means expertise just sort of spontaneously emerges. (Seriously).</p>\n<p>So. What might AI coding be good for?</p>\n<p>Well, in small cases where you <em>don\u2019t</em> care as much about correctness and for low-stakes sure, it\u2019s fine. </p>\n<p>If you want to use it for prototyping something that you don\u2019t use in production, sure, because then you can prototype something more quickly and might realize earlier that you missed a critical thing. This is good! You have more things to provide feedback on to interrogate the tradeoffs and decisions you have to make.</p>\n<p>One way of thinking about this -- and I am thinking out loud -- is that agentic coding is a bit like a really inefficient way of modularizing software development. One way to think about this is Python or Node where there are modules or packages for anything and you can reuse code someone else has written. When done this way you have some assurance (ha, supply-chain attacks) that the code you\u2019re using works, there are tests and so on. Agentic coding has the sort of ability to provide modularization of functionality, but also in a non-deterministic sense. Instead of importing a package you can totally be lazy and tell an agent to implement it for you. That is probably not a good idea because you\u2019re losing the ability to reuse something, you\u2019re just <em>regenerating</em> something. But if it <em>looks</em> like it does the job and it does the job well-enough and it was easier to tell an agent to regenerate that functionality then I\u2019m afraid humans are going to do that. It is stupid and it is inefficient but the impulse is understandable, at least. </p>\n<p>More experienced people will use tactics like tell an agent to use an existing package or have an idea of what package they already want to use, or even implement a package that can be reused in a particular project, plus have the ability and presence of mind to check whether that package has actually been reused. And again, that\u2019s <em>if they\u2019ve decided it matters</em>. </p>\n<p>I suppose one equivalent aspect is if you can trust an agent about information retrieval. It is easier (but with no guarantees about accuracy or correctness) to ask a coding agent for best practices in the same context in which you\u2019re working than to go look up what OWASP standards, read them, and then translate them back to the work you\u2019re doing. But that\u2019s if you can be sure that the agent is returning the actual OWASP standards. Are you going to check? Well if you\u2019re going to check, why not just go read them yourself in the first place? </p>\n<p>But a lot of functions are common. A lot shouldn\u2019t be reimplemented. And that \u201cshouldn\u2019t\u201d is a mixture I think of taste and a mixture of experience and capability. Some people can keep and develop good best practices in their head and know when they\u2019re appropriate and when they\u2019re not according to the circumstance and context. For those common features, I don\u2019t know, things like reference architectures that can get you started, things like Django that Willison co-created, you just use them because they fit the problem you\u2019re trying to solve. </p>\n<p>In what circumstances is it good enough to use a coding agent to step into the place of using existing packages or frameworks? An example question I might ask is: Hey, I want to make a tool that my family wants to use. How should I go about it? And I think a problem right now is that unless you\u2019re someone who has the knowledge to say \u201cdon\u2019t fucking overengineer it and build me a fucking react app, it just needs to be some html and javascript\u201d (which is what Willison does!), then you\u2019re likely (I think!) to get something that is kind of right but also not. </p>\n<p>Sure, maybe what you get is good-enough. But I suppose the point that I\u2019ve been trying to make for the last 2,600-odd words is how you decide what good-enough is. Humans decide that using \u201cexperience\u201d which is the sum total of, I don\u2019t know, everything you\u2019ve ever experienced? And then some sort of decision-making process that figures out what to prioritize and what to de-prioritize. My standing point right now is that no model has anywhere near the capability to match a human in terms of that experience. A lot of discussion here is about <em>world models</em> and <em>embodiment</em> which is to say that if you want a machine to make suggestions (or worse, decisions) about things that affect humans, then it would be good for those machines to have the best understanding of the world in which humans live. The pitch from AI companies right now is that \u201cgood enough\u201d for that world model is \u201cwhatever you can access on the internet by hook or crook\u201d, and I think that\u2019s a combination of a business decision (driven by, you know, wanting to make money) and a particular mental outlook and philosophy of a particular temperament which we may as well loosely label as \u201coverly STEM-focussed and reductive\u201d that <em>of course</em> the internet represents the sum of human experience and is good enough. <strong>Clearly</strong> there are people who disagree. I am one of them. And yes, I will acknowledge that some of the things on the internet are video of things that happen in the real world, but all of that video on the internet is the result of a human editorial decision about what\u2019s important enough to upload <em>even if it\u2019s mundane</em>. </p>\n<p>Look, let\u2019s segue. It\u2019s not as if this isn\u2019t all over the place anyway.</p>\n<h2>1.2 The Unreasonable Effectiveness of Actually Caring and Giving a Damn</h2>\n<p>I am fighting a losing battle against good-enough. I wrote about it not too long ago<sup id=\"fnref:good\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:good\">4</a></sup>. Dan Sinker wrote eloquently (i.e. in a Dan Sinker-y way) about it in The Who Cares Era<sup id=\"fnref:whocares\"><a class=\"footnote-ref\" href=\"https://newsletter.danhon.com/rss#fn:whocares\">5</a></sup>. </p>\n<p>I was talking today with an organization design professional and the perils of being a systems thinker. She was talking about seeing baggage claim at an airport and realizing that it could be organized in a different way so people wouldn\u2019t have to wait so long. I talked about how I have a hobby of taking pictures of signs people have to put on things, like on the inside of the door at a hospital toilet where a makeshift sign very clearly tells you how to lock the door, because how you\u2019d assume locks it totally does not. </p>\n<p>Here\u2019s a story about the door. The door gets bought because the building needs a door and the requirements for the door in this case are, say, \u201cis a powered door suitable for an accessible single-user bathroom\u201d and then presumably the physical requirements. Maybe an architect puts these requirements together or the general contractor and then the client signs off on them and then ta-da you\u2019ve got a renovated ER wing. </p>\n<p>But the door is a shit door because hey guess what -- now, this is a bit facetious -- nobody thought about how a door is supposed to work and made a bunch of assumptions. I get we\u2019re all busy. I get we\u2019re all burned out. But I genuinely believe that if someone actually gave a damn and had thought things through then the nurses (invariably this stuff is done by the people who have the most contact with the public using a service or the users or whomever) wouldn\u2019t have to make a fucking sign and keep making sure that the sign is visible. Just get a fucking door that works properly.</p>\n<p>It is horrible that it feels like a luxury to be able to care in your work. No, wait. People do care. It is horrible that it feels like a luxury to <em>actually</em> care in your work. </p>\n<p>I mean, it\u2019s not as if you\u2019re working at the world\u2019s largest retailer that also happens to be obsessively focussed on the customer. Because that retailer <em>definitely</em> shows signs of caring.</p>\n<hr/>\n<p>YES. I beat the last newsletter episode and we\u2019re at ~3,300 words for this one.</p>\n<p>I am that particular combination of angry and motivated, which I\u2019m reminded is the point of anger in the first place: something is not the way you want it to be and now you have some energy to deal with it. (Hopefully productively, usefully, and without harming anyone. If not, go get some good therapy).</p>\n<p>How are you?</p>\n<hr/>\n<h2>Let\u2019s fix things together</h2>\n<p>Aside from my <a href=\"https://www.verylittlegravitas.com\" target=\"_blank\">regular consulting</a>, I also do <a href=\"https://www.verylittlegravitas.com/how-people-work\" target=\"_blank\">team workshops</a> and individual <a href=\"https://www.verylittlegravitas.com/how-people-work/coaching\" target=\"_blank\">coaching</a> based on the workshop curriculum. Get in touch if you\u2019d like to find out more about how to spend that newly reset professional development and training budget you\u2019ve got.</p>\n<div class=\"footnote\">\n<hr/>\n<ol>\n<li id=\"fn:picnic\">\n<p><a href=\"https://productpicnic.beehiiv.com/\" target=\"_blank\">Home | The Product Picnic</a> (<a href=\"http://archive.is/latest/https://productpicnic.beehiiv.com/\" target=\"_blank\">archive.is</a>), Pavel Samsonov\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:picnic\" title=\"Jump back to footnote 1 in the text\">\u21a9</a></p>\n</li>\n<li id=\"fn:quoted\">\n<p><a href=\"https://bsky.app/profile/kevinr.free-dissociation.com/post/3mcdlatjmx22b\" target=\"_blank\">(3) Post by @kevinr.free-dissociation.com \u2014 Bluesky</a> (<a href=\"http://archive.is/latest/https://bsky.app/profile/kevinr.free-dissociation.com/post/3mcdlatjmx22b\" target=\"_blank\">archive.is</a>), Kevin Riggle, 13 January 2026\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:quoted\" title=\"Jump back to footnote 2 in the text\">\u21a9</a></p>\n</li>\n<li id=\"fn:iris\">\n<p><a href=\"https://deadsimpletech.com/blog/week_with_opencode\" target=\"_blank\">My week with opencode | deadSimpleTech</a> (<a href=\"http://archive.is/latest/https://deadsimpletech.com/blog/week_with_opencode\" target=\"_blank\">archive.is</a>), Iris Meredith, 13 January 2026\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:iris\" title=\"Jump back to footnote 3 in the text\">\u21a9</a><a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref2:iris\" title=\"Jump back to footnote 3 in the text\">\u21a9</a></p>\n</li>\n<li id=\"fn:good\">\n<p><a href=\"https://newsletter.danhon.com/archive/s20e09-an-end-of-year-opinion-about-ai-because/\" target=\"_blank\">s20e09: An End Of Year Opinion About AI Because Why Not; Good Enough Mitigation of Reasonably Foreseeable Harm</a> (<a href=\"http://archive.is/latest/https://newsletter.danhon.com/archive/s20e09-an-end-of-year-opinion-about-ai-because/\" target=\"_blank\">archive.is</a>), me, 29 December 2025\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:good\" title=\"Jump back to footnote 4 in the text\">\u21a9</a></p>\n</li>\n<li id=\"fn:whocares\">\n<p><a href=\"https://dansinker.com/posts/2025-05-23-who-cares/\" target=\"_blank\">The Who Cares Era | dansinker.com</a> (<a href=\"http://archive.is/latest/https://dansinker.com/posts/2025-05-23-who-cares/\" target=\"_blank\">archive.is</a>), Dan Sinker, 23 May 2025\u00a0<a class=\"footnote-backref\" href=\"https://newsletter.danhon.com/rss#fnref:whocares\" title=\"Jump back to footnote 5 in the text\">\u21a9</a></p>\n</li>\n</ol>\n</div>",
      "image": "https://placehold.co/800x600/111/333?text=No+Image"
    }
  ],
  "dailyBriefing": [
    {
      "headline": "From XKCD, some common sailing rigs, including the ketch, schooner, offset rig,...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048183-from-xkcd-some-common-sai"
    },
    {
      "headline": "By All Measures. &#8220;Our scales are too imbalanced; we are unable to...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048178-by-all-measures-our-scale"
    },
    {
      "headline": "Many of us have &#8220;lost the future&#8221; during the radical uncertainty brought...",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048186-many-of-us-have-lost"
    },
    {
      "headline": "Casting is dead. Long live casting!",
      "source": "The Verge",
      "link": "https://www.theverge.com/column/861948/casting-netflix-dead"
    },
    {
      "headline": "The Florentine Codex",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/the-florentine-codex"
    },
    {
      "headline": "Here are the best Apple Watch deals available right now",
      "source": "The Verge",
      "link": "https://www.theverge.com/21289209/best-apple-watch-deals"
    },
    {
      "headline": "NordVPN Coupons and Deals: 77% Off in January 2026",
      "source": "WIRED",
      "link": "https://www.wired.com/story/nordvpn-coupon/"
    },
    {
      "headline": "Visualizations of the growing undersea network of submarine cables, 2013-2025....",
      "source": "kottke.org",
      "link": "https://kottke.org/26/01/0048170-visualizations-of-the-gro"
    },
    {
      "headline": "30% VistaPrint Coupon & Promo Codes | January 2026",
      "source": "WIRED",
      "link": "https://www.wired.com/story/vistaprint-coupon-code/"
    },
    {
      "headline": "Meta has discontinued its metaverse for work, too",
      "source": "The Verge",
      "link": "https://www.theverge.com/tech/863209/meta-has-discontinued-its-metaverse-for-work-too"
    }
  ],
  "artInterstitials": [
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/860/787/113/589/212/original/d5b219b113839256.jpg",
    "https://files.mastodon.social/media_attachments/files/115/899/794/961/226/136/original/65278c7a34fc73f3.jpeg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/901/268/049/415/802/original/dc71b03f3af3c7b2.jpg",
    "https://s3.eu-central-2.wasabisys.com/mastodonworld/media_attachments/files/115/883/943/202/918/880/original/43c4fae3a9969207.jpg"
  ]
}